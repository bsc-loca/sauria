{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710b8119",
   "metadata": {},
   "source": [
    "# INT8, 32x32 VERSION EXAMPLE\n",
    "\n",
    "This notebook follows the same structure as `example_basic`, but showcases how to use the accelerator with a different arithmetic (int8 instead of FP16) and array size (32x32 instead of 8x16).\n",
    "\n",
    "Note that requantization inside the accelerator is not supported (yet), so when using int8 arithmetic for the inputs, the output partial sums use 32 bits (16 for the multiplication plus 16 to avoid overflows in the reduction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3226901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the dependencies we need\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import dotenv\n",
    "\n",
    "# LOAD SYSTEM ENVIRONMENT VARIABLES - To compile Verilator from here\n",
    "dotenv.load_dotenv('../env', override=True)\n",
    "\n",
    "sys.path.insert(1, './../') # To find the libraries inside Python folder\n",
    "import src.hw_versions as hwv\n",
    "import src.sauria_lib as slib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5d6ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Version - See 'Python/versions/hw_versions.py'\n",
    "sauria_version = 'int8_32x32'\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "os.chdir(\"../../test/verilator\")\n",
    "f1 = open(\"verilator_compile.log\",\"w\")\n",
    "subprocess.call([\"sh\",\"./compile_sauria.sh\",sauria_version],stdout=f1)\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3cb3cc83",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 64])\n",
      "tensor([[[-105853,   41891,  -61168],\n",
      "         [  50246,  161502,  -12996],\n",
      "         [ -42250,   13467,   39359]],\n",
      "\n",
      "        [[ -73952,  143520, -172990],\n",
      "         [-107578,    8750,    1030],\n",
      "         [  14800,   17017,  -70818]],\n",
      "\n",
      "        [[ 162033,   31859,  -47837],\n",
      "         [ -28519, -374222,  137459],\n",
      "         [ -59825,  130661,   54387]]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Convolution options:\n",
    "C_in = 64       # Input Channels\n",
    "C_out = 64      # Output Channels\n",
    "Kh,Kw = 3,3     # Kernel size\n",
    "s = 1           # Strides\n",
    "d = 1           # Dilation coefficient\n",
    "#p = 0          # Padding (UNSUPPORTED ATM!)\n",
    "\n",
    "# Define pytorch convolutional layer (randomly initialized weights & biases)\n",
    "# B_conv_torch = torch.nn.Conv2d(C_in, C_out, (Kh, Kw), stride=s, dilation=d, dtype=torch.int8)\n",
    "\n",
    "# Output tensor shape\n",
    "Cw = 64         # Output tensor width\n",
    "Ch = 64         # Output tensor height\n",
    "\n",
    "# Input tensor shape determined by output tensor shape\n",
    "Aw = (1+s*(Cw-1)) + (1+d*(Kw-1)) - 1\n",
    "Ah = (1+s*(Ch-1)) + (1+d*(Kh-1)) - 1\n",
    "\n",
    "# Randomly generate input tensors\n",
    "tensor_A_torch = torch.randint(-127,127, (C_in, Ah, Aw), dtype=torch.int8)\n",
    "\n",
    "# Randomly generate weights and biases\n",
    "tensor_B_torch = torch.randint(-127,127, (C_out, C_in, Kh, Kw), dtype=torch.int8)\n",
    "tensor_bias_torch = torch.randint(-127,127, (C_out, 1, 1), dtype=torch.int8)\n",
    "\n",
    "# Perform convolution with Pytorch and print result\n",
    "tensor_C_torch = tensor_bias_torch + torch.nn.functional.conv2d(tensor_A_torch.double(),tensor_B_torch.double(),stride=s,padding=0,dilation=d)\n",
    "tensor_C_torch = tensor_C_torch.int()\n",
    "\n",
    "print(tensor_C_torch.shape)\n",
    "print(tensor_C_torch[:3,:3,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b41250b6",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 64)\n",
      "[[[-0x19d7d 0xa3a3 -0xeef0]\n",
      "  [0xc446 0x276de -0x32c4]\n",
      "  [-0xa50a 0x349b 0x99bf]]\n",
      "\n",
      " [[-0x120e0 0x230a0 -0x2a3be]\n",
      "  [-0x1a43a 0x222e 0x406]\n",
      "  [0x39d0 0x4279 -0x114a2]]\n",
      "\n",
      " [[0x278f1 0x7c73 -0xbadd]\n",
      "  [-0x6f67 -0x5b5ce 0x218f3]\n",
      "  [-0xe9b1 0x1fe65 0xd473]]]\n"
     ]
    }
   ],
   "source": [
    "# Input tensor is the same, but converted to numpy\n",
    "tensor_A = np.array(tensor_A_torch.detach())\n",
    "\n",
    "# Weights tensor is obtained from the conv layer (randomly generated)\n",
    "tensor_B = np.array(tensor_B_torch.detach())\n",
    "\n",
    "# Bias can be added by preloading data into the array\n",
    "# (This is OPTIONAL! It adds the cost of replicating the data!)\n",
    "# (However, it is useful as an example of data preloading)\n",
    "bias_numpy = np.array(tensor_bias_torch.detach())\n",
    "preload_C = np.zeros([C_out,Ch,Cw])\n",
    "preload_C[:,:,:] = np.reshape(bias_numpy,[C_out,1,1])\n",
    "\n",
    "# Convert result into numpy to compare\n",
    "tensor_C = np.array(tensor_C_torch.detach())\n",
    "\n",
    "print(tensor_C.shape)\n",
    "print(tensor_C[:3,:3,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1376c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B_w': 3, 'B_h': 3, 'C_w': 64, 'C_h': 64, 'C_c': 64, 'A_w': 66, 'A_h': 66, 'A_c': 64, 'AB_c': 64, 'd': 1, 's': 1, 'w_til': 64, 'h_til': 8, 'c_til': 32, 'k_til': 64, 'A_w_til': 66, 'A_h_til': 10, 'X_ext_tiles': 1, 'Y_ext_tiles': 8, 'K_ext_tiles': 1, 'C_ext_tiles': 2, 'N_total_tiles': 16, 'B_w_eff': 3, 'B_h_eff': 3, 'X_int_tiles': 2, 'Y_int_tiles': 8, 'K_int_tiles': 2, 'N_cswitch': 32, 'X_used': 32, 'Y_used': 32, 'preload_en': True, 'Dil_pat': 16140901064495857664, 'rows_active': 4294967295, 'cols_active': 4294967295, 'lwoffs': array([0x0, 0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8, 0x9, 0xa, 0xb, 0xc,\n",
      "       0xd, 0xe, 0xf, 0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17,\n",
      "       0x18, 0x19, 0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f]), 'thres': 0}\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of hardware parameters describing the version of SAURIA\n",
    "HW_PARAMS = hwv.get_params(sauria_version)\n",
    "\n",
    "# Array with the tensor shapes to compute\n",
    "tensor_shapes = [tensor_A.shape, tensor_B.shape, tensor_C.shape]\n",
    "\n",
    "# Dictionary describing the tiling sizes\n",
    "TILING_DICT = {\n",
    "    'C_tile_shape'  :   [64,8,64],  #[C_out, Ch, Cw]\n",
    "    'tile_cin'      :   64,\n",
    "    'X_used'        :   32,\n",
    "    'Y_used'        :   32\n",
    "}\n",
    "\n",
    "# Dictionary fully describing the convolution to compute\n",
    "CONV_DICT = slib.get_conv_dict(tensor_shapes, TILING_DICT, HW_PARAMS, d=d, s=s, preloads=True)\n",
    "\n",
    "print(CONV_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf65d670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              TEST PASSED\n",
      "\n",
      "****************************************\n",
      "          SAURIA STATISTICS\n",
      "****************************************\n",
      "Total cycles:\t\t\t\t213534\n",
      "Total operations:\t\t\t301989888\n",
      "Average Throughput:\t\t\t1414.25 OP/cycle (69.06 %)\n",
      "\n",
      "Number of tiles:\t\t\t16\n",
      "Core stall cycles:\t\t\t4352 (2.04 %)\n",
      "Memory/CGF stall cycles:\t\t61646 (28.87 %)\n",
      "\n",
      "SAURIA memory capacity (A|B|C):\t\t64.0 | 64.0 | 128.0 [kB]\n",
      "Utilized memory:\t\t\t20.625 | 18.0 | 128.0 [kB] (32.23 | 28.12 | 100.00 [%])\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import src.config_helper as cfg\n",
    "import src.data_helper as dh\n",
    "reload(slib)\n",
    "reload(hwv)\n",
    "reload(cfg)\n",
    "reload(dh)\n",
    "\n",
    "SAURIA_outputs, SAURIA_stats = slib.Conv2d_SAURIA(tensor_A, tensor_B, preload_C, tensor_C, CONV_DICT, HW_PARAMS, generate_vcd=True, print_statistics=True, silent=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c237660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Pytorch:\n",
      "[[[0x8032 0x1ec2f -0x1e796]\n",
      "  [-0x406b 0x8eed -0xac7b]\n",
      "  [0x1e1e -0x178a -0xee5c]]\n",
      "\n",
      " [[0x35439 -0x9405 -0xdc41]\n",
      "  [-0x14ee0 0x10ac9 0xad54]\n",
      "  [-0x7265 -0x113e5 -0x42f5]]\n",
      "\n",
      " [[0x16ee7 0xe9ea -0x11b82]\n",
      "  [-0xf875 0x955c -0x8eca]\n",
      "  [0x7dbd 0x4da5 0x3305d]]]\n",
      "\n",
      "From SAURIA:\n",
      "[[[0x8032 0x1ec2f -0x1e796]\n",
      "  [-0x406b 0x8eed -0xac7b]\n",
      "  [0x1e1e -0x178a -0xee5c]]\n",
      "\n",
      " [[0x35439 -0x9405 -0xdc41]\n",
      "  [-0x14ee0 0x10ac9 0xad54]\n",
      "  [-0x7265 -0x113e5 -0x42f5]]\n",
      "\n",
      " [[0x16ee7 0xe9ea -0x11b82]\n",
      "  [-0xf875 0x955c -0x8eca]\n",
      "  [0x7dbd 0x4da5 0x3305d]]]\n",
      "\n",
      "Average absolute error:\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Print and compare to Pytorch result\n",
    "print(\"From Pytorch:\")\n",
    "print(tensor_C[:3,:3,:3])\n",
    "\n",
    "print(\"\\nFrom SAURIA:\")\n",
    "SAURIA_outputs = SAURIA_outputs.astype(np.int32)\n",
    "print(SAURIA_outputs[:3,:3,:3])\n",
    "\n",
    "print(\"\\nAverage absolute error:\")\n",
    "print(np.abs(SAURIA_outputs - tensor_C).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sauria-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
