{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "671df266",
   "metadata": {},
   "source": [
    "# SAURIA SIMULATION EXAMPLE\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we'll take a look at a basic example for simulating convolutions with SAURIA via RTL emulation with Verilator.\n",
    "\n",
    "To perform simulations with SAURIA, we use a custom made framework based on Python and Verilator. Experiments and tests are written and executed in Python, and our Verilator testbench emulates the execution of convolutions in hardware. As depicted in the figure below, we use temporary .txt files in order to transfer data between the two environments.\n",
    "\n",
    "<img src=\"figures/methodology.svg\" alt=\"drawing\" width=\"750\"/>\n",
    "\n",
    "As an example, we will use this framework to execute an arbitrary convolution operation with SAURIA and obtain the results computed by the hardware and its performance statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6fdc0",
   "metadata": {},
   "source": [
    "&#x26A0; *IMPORTANT* &#x26A0;\n",
    "\n",
    "Before running the cells below, please make sure that all the requirements and installation steps described in the README have been performed, and that the Python kernel selected in the Jupyter Notebook is \"sauria-env\" from 'Python/sauria-env/bin/python'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3226901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the dependencies we need\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import dotenv\n",
    "\n",
    "# LOAD SYSTEM ENVIRONMENT VARIABLES - To compile Verilator from here\n",
    "dotenv.load_dotenv('../env', override=True)\n",
    "\n",
    "sys.path.insert(1, './../') # To find the libraries inside Python folder\n",
    "import src.hw_versions as hwv\n",
    "import src.sauria_lib as slib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d9c2d",
   "metadata": {},
   "source": [
    "## Build SAURIA in Verilator\n",
    "\n",
    "Before starting the test, we need to make sure that the Verilator model of our hardware has been compiled, so that we can perform RTL emulations.\n",
    "\n",
    "You can do that by executing the following commands in your terminal:\n",
    "\n",
    "```\n",
    "cd test/verilator\n",
    "./compile_sauria.sh\n",
    "```\n",
    "\n",
    "*Alternatively*, you can also run the following code cell, which does the same from the context of this Notebook, via `subprocess`.\n",
    "\n",
    "This only needs to be performed once for every version of the RTL, so if you have built SAURIA before, you can skip this step!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d6ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Version - See 'Python/versions/hw_versions.py'\n",
    "sauria_version = 'FP16_8x16'\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "os.chdir(\"../../test/verilator\")\n",
    "f1 = open(\"verilator_compile.log\",\"w\")\n",
    "subprocess.call([\"sh\",\"./compile_sauria.sh\",sauria_version],stdout=f1)\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a283e6f7",
   "metadata": {},
   "source": [
    "## Define an example convolution\n",
    "\n",
    "To test SAURIA with some random data, let's define an arbitrary convolution. We will choose small channel and spatial sizes so that the emulation does not take very long.\n",
    "\n",
    "As a reference, we will perform the convolution using Pytorch, and later compare these results to the output of SAURIA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb3cc83",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Convolution options:\n",
    "C_in = 32       # Input Channels\n",
    "C_out = 32      # Output Channels\n",
    "Kh,Kw = 3,3     # Kernel size\n",
    "s = 1           # Strides\n",
    "d = 1           # Dilation coefficient\n",
    "#p = 0           # Padding (UNSUPPORTED ATM!)\n",
    "\n",
    "# Define pytorch convolutional layer (randomly initialized weights & biases)\n",
    "B_conv_torch = torch.nn.Conv2d(C_in, C_out, (Kh, Kw), stride=s, dilation=d)\n",
    "\n",
    "# Output tensor shape\n",
    "Cw = 8         # Output tensor width\n",
    "Ch = 8          # Output tensor height\n",
    "\n",
    "# Input tensor shape determined by output tensor shape\n",
    "Aw = (1+s*(Cw-1)) + (1+d*(Kw-1)) - 1\n",
    "Ah = (1+s*(Ch-1)) + (1+d*(Kh-1)) - 1\n",
    "\n",
    "# Randomly generate input tensor\n",
    "tensor_A_torch = torch.randn(C_in, Ah, Aw, dtype=torch.float32)\n",
    "\n",
    "# Perform convolution with Pytorch and print result\n",
    "tensor_C_torch = B_conv_torch(tensor_A_torch)\n",
    "\n",
    "print(tensor_C_torch.shape)\n",
    "print(tensor_C_torch[:3,:3,:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73c9b23",
   "metadata": {},
   "source": [
    "## Convert tensors to numpy\n",
    "\n",
    "The SAURIA Python library works with numpy arrays, so first we need to convert the Pytorch tensors into numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41250b6",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Input tensor is the same, but converted to numpy\n",
    "tensor_A = np.array(tensor_A_torch.detach())\n",
    "\n",
    "# Weights tensor is obtained from the conv layer (randomly generated)\n",
    "tensor_B = np.array(B_conv_torch.weight.detach())\n",
    "\n",
    "# Bias can be added by preloading data into the array\n",
    "# (This is OPTIONAL! It adds the cost of replicating the data!)\n",
    "# (However, it is useful as an example of data preloading)\n",
    "bias_numpy = np.array(B_conv_torch.bias.detach())\n",
    "preload_C = np.zeros([C_out,Ch,Cw])\n",
    "preload_C[:,:,:] = np.reshape(bias_numpy,[C_out,1,1])\n",
    "\n",
    "# Convert result into numpy to compare\n",
    "tensor_C = np.array(tensor_C_torch.detach())\n",
    "\n",
    "print(tensor_C.shape)\n",
    "print(tensor_C[:3,:3,:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761f74e4",
   "metadata": {},
   "source": [
    "## Define the SAURIA configuration\n",
    "\n",
    "Before running the hardware emulation, we need to generate the configuration dictionaries that describe the operation of SAURIA. Our library defines 3 configuration structures:\n",
    "\n",
    "* **HW_PARAMS** - Describes the HW parameters of a specific SAURIA configuration. Changing these values requires changing the hardware, and therefore recompiling the Verilator model. Currently, only the \"FP16_8x16\" is fully integrated into our framework (*more coming soon!*).\n",
    "\n",
    "* **TILING_DICT** - Describes the size and configuration of the tiles that will be used to partition the full convolution so that it fits into the hardware. Ideally, this should be done by a tiling algorithm that automatically discovers the optimal tile size to maximize throughput, but that implementation is still a work-in-progress, so for now we will define it by hand.\n",
    "\n",
    "* **CONV_DICT** - Describes all the convolution-related variables that SAURIA needs to perform an operation. It can be obtained by using the function `get_conv_dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1376c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of hardware parameters describing the version of SAURIA\n",
    "HW_PARAMS = hwv.get_params(sauria_version)\n",
    "\n",
    "# Array with the tensor shapes to compute\n",
    "tensor_shapes = [tensor_A.shape, tensor_B.shape, tensor_C.shape]\n",
    "\n",
    "# Dictionary describing the tiling sizes\n",
    "TILING_DICT = {\n",
    "    'C_tile_shape'  :   [32,4,8],  #[C_out, Ch, Cw]\n",
    "    'tile_cin'      :   32,\n",
    "    'X_used'        :   16,\n",
    "    'Y_used'        :   8\n",
    "}\n",
    "\n",
    "# Dictionary fully describing the convolution to compute\n",
    "CONV_DICT = slib.get_conv_dict(tensor_shapes, TILING_DICT, HW_PARAMS, d=d, s=s, preloads=True)\n",
    "\n",
    "print(CONV_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f919acff",
   "metadata": {},
   "source": [
    "## RTL Emulation & Performance metrics\n",
    "\n",
    "Now that everything is defined, we can use our library to run the convolution using SAURIA via Verilator emulation.\n",
    "\n",
    "With the option `print_statistics` set to `True`, the function will print some statistics of the execution, such as the average throughput, total numer of cycles and number of stalls. Additionally, setting `generate_vcd=True` will generate a VCD file with the waveforms of the accelerator, which can be used later for analysis.\n",
    "\n",
    "\n",
    "*(NOTE: generating the VCD file makes emulation much slower, and may result in gigantic files, so be careful with long simulations!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf65d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAURIA_outputs, SAURIA_stats = slib.Conv2d_SAURIA(tensor_A, tensor_B, preload_C, tensor_C, CONV_DICT, HW_PARAMS, generate_vcd=True, print_statistics=True, silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86727dec",
   "metadata": {},
   "source": [
    "&#x1F914; Note that the performance of SAURIA in this configuration is not stellar: its average utilization is about 55%. As indicated by the memory stall cycles, this happens because, in this particular configuration, SAURIA spends over 40% of the time waiting for configuration or memory transactions to finish (mostly memory).\n",
    "\n",
    "In this case, the main reason is that the convolution and tile shapes are too small to fully exploit the capabilities of SAURIA. Note that the memory utilization of the internal memories of SAURIA is quite small, so we are not achieving the full potential of the accelerator. The last code cell of this Notebook contains an example with a larger convolution, which achieves a much higher utilization and throughput. &#x1F680;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31797cc",
   "metadata": {},
   "source": [
    "## Compare results\n",
    "\n",
    "Now that we have some results from SAURIA, we can compare them to the ones we obtained directly using Pytorch.\n",
    "\n",
    "The results will not be the same for two main reasons:\n",
    "\n",
    "1. Pytorch uses FP32 values, while the base configuration of SAURIA used in this example uses FP16. The difference in precision will cause SAURIA's outputs to be less accurate.\n",
    "\n",
    "2. In floating-point arithmetic, the order of operations matters. Hence, even if the precisions were the same, we would get slightly different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c237660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print and compare to Pytorch result\n",
    "print(\"From Pytorch:\")\n",
    "print(tensor_C[:3,:3,:3])\n",
    "\n",
    "print(\"\\nFrom SAURIA:\")\n",
    "print(SAURIA_outputs[:3,:3,:3])\n",
    "\n",
    "print(\"\\nAverage absolute error:\")\n",
    "print(np.abs(SAURIA_outputs - tensor_C).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bfcc5d",
   "metadata": {},
   "source": [
    "## Check the waveforms\n",
    "\n",
    "We can use the open-source software `gtkwave` to explore the waveforms exported as a VCD file, by running the following commands on our terminal:\n",
    "\n",
    "```\n",
    "cd test/verilator\n",
    "gtkwave -g new.vcd\n",
    "```\n",
    "\n",
    "With the waves we can confirm that the reason for the low utilization is the size of the convolution:\n",
    "\n",
    "<img src=\"figures/gtwaves.png\" alt=\"drawing\" width=\"900\"/>\n",
    "\n",
    "The initial ramp-up time of bringing the frist tiles into the accelerator takes about 40% of the total time. Since the computation is short and the number of tiles is low, this ramp-up time is not amortized enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa60ae",
   "metadata": {},
   "source": [
    "## Test with larger convolution\n",
    "\n",
    "As promised, now let's repeat the experiment with a slightly larger convolution and tile size. The function `generate_and_run_test` will automatically generate random stimuli so that we don't need to do that again.\n",
    "\n",
    "The emulation may take a while, so go grab a coffee in the meantime! &#x2615;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54904ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution options:\n",
    "C_in = 64       # Input Channels\n",
    "C_out = 128     # Output Channels\n",
    "Kh,Kw = 3,3     # Kernel size\n",
    "s = 1           # Strides\n",
    "d = 1           # Dilation coefficient\n",
    "p = 0           # Padding (UNSUPPORTED ATM!)\n",
    "\n",
    "# Output tensor shape\n",
    "Cw = 32         # Output tensor width\n",
    "Ch = 32         # Output tensor height\n",
    "\n",
    "# Input tensor shape determined by output tensor shape\n",
    "Aw = (1+s*(Cw-1)) + (1+d*(Kw-1)) - 1\n",
    "Ah = (1+s*(Ch-1)) + (1+d*(Kh-1)) - 1\n",
    "\n",
    "tensor_shapes = [\n",
    "    [C_in,Ah,Aw],           # A tensor (inputs)\n",
    "    [C_out,C_in,Kh,Kw],     # B tensor (outputs)\n",
    "    [C_out,Ch,Cw]           # C tensor (psums)\n",
    "]\n",
    "\n",
    "TILING_DICT = {\n",
    "    'C_tile_shape'  :   [32,8,32],  #[C_out, Ch, Cw]\n",
    "    'tile_cin'      :   32,\n",
    "    'loop_order'    :   1,\n",
    "    'X_used'        :   16,\n",
    "    'Y_used'        :   8\n",
    "}\n",
    "\n",
    "SAURIA_outputs_large, SAURIA_stats_large, partial_macs = slib.generate_and_run_test(tensor_shapes, TILING_DICT, d, s, HW_PARAMS, preload=True, generate_vcd=False, print_statistics=True, silent=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sauria-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
