{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "710b8119",
   "metadata": {},
   "source": [
    "# INT8, 32x32 VERSION EXAMPLE\n",
    "\n",
    "This notebook follows the same structure as `example_basic`, but showcases how to use the accelerator with a different arithmetic (int8 instead of FP16) and array size (32x32 instead of 8x16).\n",
    "\n",
    "Note that requantization inside the accelerator is not supported (yet), so when using int8 arithmetic for the inputs, the output partial sums use 32 bits (16 for the multiplication plus 16 to avoid overflows in the reduction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3226901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the dependencies we need\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import dotenv\n",
    "\n",
    "# LOAD SYSTEM ENVIRONMENT VARIABLES - To compile Verilator from here\n",
    "dotenv.load_dotenv('../env', override=True)\n",
    "\n",
    "sys.path.insert(1, './../') # To find the libraries inside Python folder\n",
    "import src.hw_versions as hwv\n",
    "import src.sauria_lib as slib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c11f52",
   "metadata": {},
   "source": [
    "### Compile verilator model\n",
    "\n",
    "Remember that this only needs to be done once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d6ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Version - See 'Python/versions/hw_versions.py'\n",
    "sauria_version = 'int8_32x32'\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "os.chdir(\"../../test/verilator\")\n",
    "f1 = open(\"verilator_compile.log\",\"w\")\n",
    "subprocess.call([\"sh\",\"./compile_sauria.sh\",sauria_version],stdout=f1)\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda72db6",
   "metadata": {},
   "source": [
    "### Define convolution & generate random tensors\n",
    "\n",
    "This time, we will use int8 values so we generate them directly with `randint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb3cc83",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Convolution options:\n",
    "C_in = 64       # Input Channels\n",
    "C_out = 64      # Output Channels\n",
    "Kh,Kw = 3,3     # Kernel size\n",
    "s = 1           # Strides\n",
    "d = 1           # Dilation coefficient\n",
    "#p = 0          # Padding (UNSUPPORTED ATM!)\n",
    "\n",
    "# Output tensor shape\n",
    "Cw = 64         # Output tensor width\n",
    "Ch = 64         # Output tensor height\n",
    "\n",
    "# Input tensor shape determined by output tensor shape\n",
    "Aw = (1+s*(Cw-1)) + (1+d*(Kw-1)) - 1\n",
    "Ah = (1+s*(Ch-1)) + (1+d*(Kh-1)) - 1\n",
    "\n",
    "# Randomly generate input tensors\n",
    "tensor_A_torch = torch.randint(-127,127, (C_in, Ah, Aw), dtype=torch.int8)\n",
    "\n",
    "# Randomly generate weights and biases\n",
    "tensor_B_torch = torch.randint(-127,127, (C_out, C_in, Kh, Kw), dtype=torch.int8)\n",
    "tensor_bias_torch = torch.randint(-127,127, (C_out, 1, 1), dtype=torch.int8)\n",
    "\n",
    "# Perform convolution with Pytorch and print result\n",
    "tensor_C_torch = tensor_bias_torch + torch.nn.functional.conv2d(tensor_A_torch.double(),tensor_B_torch.double(),stride=s,padding=0,dilation=d)\n",
    "tensor_C_torch = tensor_C_torch.int()\n",
    "\n",
    "print(tensor_C_torch.shape)\n",
    "print(tensor_C_torch[:3,:3,:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa16a2e",
   "metadata": {},
   "source": [
    "### Convert tensors to numpy\n",
    "\n",
    "As in the FP16 case, we convert the tensors to numpy arrays before passing them to the SAURIA library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41250b6",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Input tensor is the same, but converted to numpy\n",
    "tensor_A = np.array(tensor_A_torch.detach())\n",
    "\n",
    "# Weights tensor is obtained from the conv layer (randomly generated)\n",
    "tensor_B = np.array(tensor_B_torch.detach())\n",
    "\n",
    "# Bias can be added by preloading data into the array\n",
    "# (This is OPTIONAL! It adds the cost of replicating the data!)\n",
    "# (However, it is useful as an example of data preloading)\n",
    "bias_numpy = np.array(tensor_bias_torch.detach())\n",
    "preload_C = np.zeros([C_out,Ch,Cw])\n",
    "preload_C[:,:,:] = np.reshape(bias_numpy,[C_out,1,1])\n",
    "\n",
    "# Convert result into numpy to compare\n",
    "tensor_C = np.array(tensor_C_torch.detach())\n",
    "\n",
    "print(tensor_C.shape)\n",
    "print(tensor_C[:3,:3,:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22e6553",
   "metadata": {},
   "source": [
    "### Define the tiling configuration, generate the CONV dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1376c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of hardware parameters describing the version of SAURIA\n",
    "HW_PARAMS = hwv.get_params(sauria_version)\n",
    "\n",
    "# Array with the tensor shapes to compute\n",
    "tensor_shapes = [tensor_A.shape, tensor_B.shape, tensor_C.shape]\n",
    "\n",
    "# Dictionary describing the tiling sizes\n",
    "TILING_DICT = {\n",
    "    'C_tile_shape'  :   [64,8,64],  #[C_out, Ch, Cw]\n",
    "    'tile_cin'      :   64,\n",
    "    'X_used'        :   32,\n",
    "    'Y_used'        :   32\n",
    "}\n",
    "\n",
    "# Dictionary fully describing the convolution to compute\n",
    "CONV_DICT = slib.get_conv_dict(tensor_shapes, TILING_DICT, HW_PARAMS, d=d, s=s, preloads=True)\n",
    "\n",
    "print(CONV_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97064e85",
   "metadata": {},
   "source": [
    "### Run RTL Emulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf65d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAURIA_outputs, SAURIA_stats = slib.Conv2d_SAURIA(tensor_A, tensor_B, preload_C, tensor_C, CONV_DICT, HW_PARAMS, generate_vcd=False, print_statistics=True, silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3390137b",
   "metadata": {},
   "source": [
    "### Compare results to golden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c237660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print and compare to Pytorch result\n",
    "print(\"From Pytorch:\")\n",
    "print(tensor_C[:3,:3,:3])\n",
    "\n",
    "print(\"\\nFrom SAURIA:\")\n",
    "SAURIA_outputs = SAURIA_outputs.astype(np.int32)\n",
    "print(SAURIA_outputs[:3,:3,:3])\n",
    "\n",
    "print(\"\\nAverage absolute error:\")\n",
    "print(np.abs(SAURIA_outputs - tensor_C).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e2b06e",
   "metadata": {},
   "source": [
    "### Matrix-matrix multiplication example\n",
    "\n",
    "Now let's try to perform a matrix-matrix multiplication directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeb3191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEMM options:\n",
    "C = 512         # Input Channels\n",
    "L = 256         # Input size (number of hyperdimensional vectors)\n",
    "K = 512         # Output Channels\n",
    "\n",
    "# Generate random input matrices\n",
    "matrix_A = np.random.randint(-127,127,size=(C,L),dtype=np.int8)\n",
    "matrix_B = np.random.randint(-127,127,size=(K,C),dtype=np.int8)\n",
    "\n",
    "bias_numpy = np.random.randint(-127,127,size=(K,1),dtype=np.int8)\n",
    "\n",
    "# Compute matmul in numpy (cast to int32 to avoid overflow)\n",
    "matmul_C = np.matmul(matrix_B.astype(np.int32), matrix_A.astype(np.int32))\n",
    "\n",
    "# Add bias as a 2nd step\n",
    "# (NOTE: we will add the bias in software, so we need the matmul only result if we want to pass golden values to the library)\n",
    "matrix_C = matmul_C + bias_numpy.astype(np.int32)\n",
    "\n",
    "print(matrix_C.shape)\n",
    "print(matrix_C[:3,:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da83e6c",
   "metadata": {},
   "source": [
    "### Convolution equivalence\n",
    "\n",
    "A GEMM can be seen as a particular case of the convolution operation. The equivalence between tensor and matrix dimensions is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use SAURIA for GEMM operation, the equivalence is as follows:\n",
    "C_in = C        # Input Channels\n",
    "C_out = K       # Output Channels\n",
    "Kh,Kw = 1,1     # Kernel size           -> ALWAYS 1,1 BECAUSE THERE IS NO KERNEL!\n",
    "s = 1           # Strides               -> ALWAYS 1!\n",
    "d = 1           # Dilation coefficient  -> ALWAYS 1!\n",
    "#p = 0          # Padding (UNSUPPORTED ATM!)\n",
    "Cw = L          # Output tensor width\n",
    "Ch = 1          # Output tensor height  -> ALWAYS 1!\n",
    "Aw = Cw         # Input tensor shape is the same because there is no convolutional kernel\n",
    "Ah = Ch\n",
    "\n",
    "# Now we must simply reshape the matrices to fit the tensor template:\n",
    "matrix_A_reshaped = np.reshape(matrix_A, (C_in,Ah,Aw))\n",
    "matrix_B_reshaped = np.reshape(matrix_B, (C_out,C_in,Kh,Kw))\n",
    "matmul_C_reshaped = np.reshape(matmul_C, (C_out,Ch,Cw))\n",
    "\n",
    "# Array with the \"tensor\" shapes to compute\n",
    "tensor_shapes = [matrix_A_reshaped.shape, matrix_B_reshaped.shape, matmul_C_reshaped.shape]\n",
    "\n",
    "# Dictionary describing the tiling sizes\n",
    "TILING_DICT = {\n",
    "    'C_tile_shape'  :   [128,1,256],  #[C_out, Ch, Cw]\n",
    "    'tile_cin'      :   256,\n",
    "    'X_used'        :   32,\n",
    "    'Y_used'        :   32\n",
    "}\n",
    "\n",
    "# Dictionary fully describing the convolution to compute\n",
    "CONV_DICT = slib.get_conv_dict(tensor_shapes, TILING_DICT, HW_PARAMS, d=d, s=s, preloads=True)\n",
    "\n",
    "print(CONV_DICT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df310e4",
   "metadata": {},
   "source": [
    "### GEMM Emulation with SAURIA\n",
    "\n",
    "Now let's run the hardware emulation. To switch things up a little bit, we will add the bias externally via software, instead of preloading the bias values into the array, which is actually better for the required bandwidth.\n",
    "\n",
    "(*Note that how the bias is added does not depend on whether or not we perform a GEMM or a convolution, this is just an illustrative example for both things*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df193f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAURIA_outputs_2, SAURIA_stats_2 = slib.Conv2d_SAURIA(matrix_A_reshaped, matrix_B_reshaped, None, matmul_C_reshaped, CONV_DICT, HW_PARAMS, generate_vcd=False, print_statistics=True, silent=False)\n",
    "\n",
    "# Squeeze to reshape from [K,1,L] into [K,L]\n",
    "SAURIA_outputs_2 = SAURIA_outputs_2.squeeze()\n",
    "\n",
    "# This time we add the bias externally via software\n",
    "SAURIA_matrix = SAURIA_outputs_2 + bias_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f066f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print and compare to Numpy result\n",
    "print(\"From Pytorch:\")\n",
    "print(matrix_C[:3,:3])\n",
    "\n",
    "print(\"\\nFrom SAURIA:\")\n",
    "SAURIA_outputs_2_plusbias = SAURIA_matrix.astype(np.int32)\n",
    "print(SAURIA_outputs_2_plusbias[:3,:3])\n",
    "\n",
    "print(\"\\nAverage absolute error:\")\n",
    "print(np.abs(SAURIA_outputs_2_plusbias - matrix_C).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sauria-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
